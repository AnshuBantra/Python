{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using DuckDB in Python: A Comprehensive Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to DuckDB\n",
    "\n",
    "DuckDB is a high-performance, in-memory/in-process analytical database management system designed to execute complex analytical SQL queries fast, efficiently, and reliably over large datasets. It is often referred to as the \"SQLite for analytics\" due to its lightweight nature and ease of integration, making it ideal for analytics tasks, able to run entirely in memory or within an application.\n",
    "\n",
    "It basically means that, DuckDB can process data fast, similar to traditional databases like PostgreSQL or SQLite, but without the need for an external server process. DuckDB is particularly well-suited for data analysis tasks, making it a powerful tool for data scientists and analysts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Why DuckDB?**\n",
    "\n",
    "* **In-Process DB** : DuckDB can be embedded directly into your Python environment, which means you don't need to manage a separate database server.\n",
    "* **Columnar Storage** : It stores data in a columnar format, optimized for analytical queries.\n",
    "* **SQL support** : DuckDB fully supports SQL queries, making it easy to interact with large datasets using well-known SQL syntax.\n",
    "* **Fast and efficient** : DuckDB is designed for speed, particularly for analytical workloads like large aggregations or filtering operations.\n",
    "* **Compatible with Pandas, Parquet, and Arrow** : It supports modern data formats, enabling seamless interaction with other data science libraries.\n",
    "\n",
    "Let's explore how to use DuckDB in Python, going from installation to performing various operations like loading data, querying, and interacting with other Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "To get started with DuckDB in Python, you need to install the DuckDB Python package. You can do this using `pip` or `conda`, depending on your environment:\n",
    "\n",
    "```bash\n",
    "pip install duckdb\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```bash\n",
    "conda install python-duckdb -c conda-forge\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DuckDB Database\n",
    "\n",
    "In DuckDB, databases are either stored as files or kept in memory. For simplicity, let's first work with an **in-memory** database.\n",
    "\n",
    "```python\n",
    "import duckdb as dd\n",
    "\n",
    "# Create an in-memory DuckDB connection\n",
    "con = dd.connect(':memory:')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb as dd\n",
    "\n",
    "# Create a persistent DuckDB database\n",
    "con = dd.connect('my_database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import duckdb as dd\n",
    "\n",
    "# Running a basic SQL query\n",
    "result = dd.sql(\"SELECT 'DuckDB_is_cool' AS answer\").fetchall()\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'duckdb.duckdb.DuckDBPyRelation'>\n",
      "┌────────────────┐\n",
      "│     answer     │\n",
      "│    varchar     │\n",
      "├────────────────┤\n",
      "│ DuckDB_is_cool │\n",
      "└────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import duckdb as dd\n",
    "\n",
    "# Running a basic SQL query\n",
    "result = dd.sql(\"SELECT 'DuckDB_is_cool' AS answer\")\n",
    "print( type(result) )\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────┐\n",
      "│     ID     │\n",
      "│   int64    │\n",
      "├────────────┤\n",
      "│          0 │\n",
      "│          1 │\n",
      "│          2 │\n",
      "│          3 │\n",
      "│          4 │\n",
      "│          5 │\n",
      "│          6 │\n",
      "│          7 │\n",
      "│          8 │\n",
      "│          9 │\n",
      "│          · │\n",
      "│          · │\n",
      "│          · │\n",
      "│        990 │\n",
      "│        991 │\n",
      "│        992 │\n",
      "│        993 │\n",
      "│        994 │\n",
      "│        995 │\n",
      "│        996 │\n",
      "│        997 │\n",
      "│        998 │\n",
      "│        999 │\n",
      "├────────────┤\n",
      "│ 1000 rows  │\n",
      "│ (20 shown) │\n",
      "└────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import duckdb as db\n",
    "\n",
    "# Create a relation from a SQL query\n",
    "rel = db.sql(\"SELECT * FROM range(10_00) AS tbl(ID)\")\n",
    "\n",
    "# Display the relation\n",
    "rel.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running SQL Queries & Data Ingestion\n",
    "\n",
    "DuckDB supports standard SQL syntax, so you can run any SQL query with ease. Let's start by creating an on-file/persistent database and querying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────┬─────────┬─────────┬──────────────┬──────────────┬───────────┐\n",
       "│ database │ schema  │  name   │ column_names │ column_types │ temporary │\n",
       "│ varchar  │ varchar │ varchar │  varchar[]   │  varchar[]   │  boolean  │\n",
       "├──────────┴─────────┴─────────┴──────────────┴──────────────┴───────────┤\n",
       "│                                 0 rows                                 │\n",
       "└────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb as dd\n",
    "\n",
    "# Create / connect to database\n",
    "con = dd.connect('my_database.db')\n",
    "con.sql('SHOW ALL TABLES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by creating a table and inserting some data, manually.\n",
    "\n",
    "#### Example 1: Creating a Table and Inserting Data Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────────┬─────────┬───────────┬──────────────────────────────────────────────────────────┬───────────────────────────────────────────────┬───────────┐\n",
       "│  database   │ schema  │   name    │                       column_names                       │                 column_types                  │ temporary │\n",
       "│   varchar   │ varchar │  varchar  │                        varchar[]                         │                   varchar[]                   │  boolean  │\n",
       "├─────────────┼─────────┼───────────┼──────────────────────────────────────────────────────────┼───────────────────────────────────────────────┼───────────┤\n",
       "│ my_database │ main    │ countries │ [country, code, region, sub_region, intermediate_region] │ [VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR] │ false     │\n",
       "└─────────────┴─────────┴───────────┴──────────────────────────────────────────────────────────┴───────────────────────────────────────────────┴───────────┘"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a table\n",
    "con.execute('''\n",
    "CREATE OR REPLACE TABLE countries (\n",
    "    country VARCHAR,\n",
    "    code VARCHAR,\n",
    "    region VARCHAR,\n",
    "    sub_region VARCHAR,\n",
    "    intermediate_region VARCHAR\n",
    ");\n",
    "''')\n",
    "\n",
    "# Insert some data\n",
    "con.execute('''\n",
    "INSERT INTO countries VALUES\n",
    "('Australia', 'AUS', 'Oceania', 'Australia and New Zealand', ''),\n",
    "('India', 'IND', 'Asia', 'Southern Asia', '');\n",
    "''')\n",
    "\n",
    "con.sql('SHOW ALL TABLES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Creating a Table and Inserting Data Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────────┬─────────┬───────────┬──────────────────────────────────────────────────────────┬───────────────────────────────────────────────┬───────────┐\n",
       "│  database   │ schema  │   name    │                       column_names                       │                 column_types                  │ temporary │\n",
       "│   varchar   │ varchar │  varchar  │                        varchar[]                         │                   varchar[]                   │  boolean  │\n",
       "├─────────────┼─────────┼───────────┼──────────────────────────────────────────────────────────┼───────────────────────────────────────────────┼───────────┤\n",
       "│ my_database │ main    │ countries │ [country, code, region, sub_region, intermediate_region] │ [VARCHAR, VARCHAR, VARCHAR, VARCHAR, VARCHAR] │ false     │\n",
       "│ my_database │ main    │ employees │ [id, name, age, salary]                                  │ [INTEGER, VARCHAR, INTEGER, DOUBLE]           │ false     │\n",
       "└─────────────┴─────────┴───────────┴──────────────────────────────────────────────────────────┴───────────────────────────────────────────────┴───────────┘"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create second table\n",
    "con.execute('''\n",
    "CREATE OR REPLACE TABLE employees (\n",
    "    id INTEGER,\n",
    "    name VARCHAR,\n",
    "    age INTEGER,\n",
    "    salary DOUBLE\n",
    ");\n",
    "''')\n",
    "\n",
    "# Insert some data in second table\n",
    "con.execute('''\n",
    "INSERT INTO employees VALUES\n",
    "(1, 'Person 1', 30, 70000),\n",
    "(2, 'Person 2', 25, 55000),\n",
    "(3, 'Person 3', 35, 80000);\n",
    "''')\n",
    "\n",
    "\n",
    "# Result of showing tables after creating the second table\n",
    "con.sql('SHOW ALL TABLES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting and Working with Data directly from files\n",
    "\n",
    "In the above examples we saw, DuckDB gives us the capability to create tables and allows us to manually add data to them. However, if we are talking about large sets of data, we can ingest data from a variety of sources, including CSV, Parquet, JSON, etc. files. DuckDB lets us capture and store this data in a database. Let's start by removing the data added manually to the countries table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────┬─────────┬─────────┬────────────┬─────────────────────┐\n",
       "│ country │  code   │ region  │ sub_region │ intermediate_region │\n",
       "│ varchar │ varchar │ varchar │  varchar   │       varchar       │\n",
       "├─────────┴─────────┴─────────┴────────────┴─────────────────────┤\n",
       "│                             0 rows                             │\n",
       "└────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql('DELETE FROM countries;')\n",
    "con.sql('SELECT * FROM countries;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's insert all the values from the `countires.csv` file directly into the table and see how the data looks, afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌────────────────┬─────────┬─────────┬─────────────────┬─────────────────────┐\n",
       "│    country     │  code   │ region  │   sub_region    │ intermediate_region │\n",
       "│    varchar     │ varchar │ varchar │     varchar     │       varchar       │\n",
       "├────────────────┼─────────┼─────────┼─────────────────┼─────────────────────┤\n",
       "│ Afghanistan    │ AFG     │ Asia    │ Southern Asia   │ NULL                │\n",
       "│ Åland Islands  │ ALA     │ Europe  │ Northern Europe │ NULL                │\n",
       "│ Albania        │ ALB     │ Europe  │ Southern Europe │ NULL                │\n",
       "│ Algeria        │ DZA     │ Africa  │ Northern Africa │ NULL                │\n",
       "│ American Samoa │ ASM     │ Oceania │ Polynesia       │ NULL                │\n",
       "└────────────────┴─────────┴─────────┴─────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql('''\n",
    "        INSERT INTO countries (country, code, region, sub_region, intermediate_region) \n",
    "        (SELECT * FROM \"countries.csv\")\n",
    "''')\n",
    "con.sql('SELECT * FROM countries LIMIT 5;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with persistent data stored in files\n",
    "\n",
    "Once the data is stored in tables as persistent data, we can work with it using standard SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────────────────────────────────┬─────────┬─────────┬───────────────────────────┬─────────────────────┐\n",
       "│              country              │  code   │ region  │        sub_region         │ intermediate_region │\n",
       "│              varchar              │ varchar │ varchar │          varchar          │       varchar       │\n",
       "├───────────────────────────────────┼─────────┼─────────┼───────────────────────────┼─────────────────────┤\n",
       "│ Australia                         │ AUS     │ Oceania │ Australia and New Zealand │ NULL                │\n",
       "│ Christmas Island                  │ CXR     │ Oceania │ Australia and New Zealand │ NULL                │\n",
       "│ Cocos (Keeling) Islands           │ CCK     │ Oceania │ Australia and New Zealand │ NULL                │\n",
       "│ Heard Island and McDonald Islands │ HMD     │ Oceania │ Australia and New Zealand │ NULL                │\n",
       "│ New Zealand                       │ NZL     │ Oceania │ Australia and New Zealand │ NULL                │\n",
       "│ Norfolk Island                    │ NFK     │ Oceania │ Australia and New Zealand │ NULL                │\n",
       "└───────────────────────────────────┴─────────┴─────────┴───────────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql('''\n",
    "        SELECT  *\n",
    "            FROM\n",
    "                countries\n",
    "            WHERE\n",
    "                region = 'Oceania'\n",
    "                AND sub_region = 'Australia and New Zealand'\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Data directly from files\n",
    "\n",
    "While DuckDB can ingest data from various formats, as discussed above. DuckDB also gives a provision to read from these files into an in-memory DuckDB relation (table) and query them directly, to explore and work with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────────────────┬─────────┬─────────┬────────────┬─────────────────────┐\n",
       "│       name        │  code   │ region  │ sub-region │ intermediate-region │\n",
       "│      varchar      │ varchar │ varchar │  varchar   │       varchar       │\n",
       "├───────────────────┼─────────┼─────────┼────────────┼─────────────────────┤\n",
       "│ American Samoa    │ ASM     │ Oceania │ Polynesia  │ NULL                │\n",
       "│ Cook Islands      │ COK     │ Oceania │ Polynesia  │ NULL                │\n",
       "│ French Polynesia  │ PYF     │ Oceania │ Polynesia  │ NULL                │\n",
       "│ Niue              │ NIU     │ Oceania │ Polynesia  │ NULL                │\n",
       "│ Pitcairn          │ PCN     │ Oceania │ Polynesia  │ NULL                │\n",
       "│ Samoa             │ WSM     │ Oceania │ Polynesia  │ NULL                │\n",
       "│ Tokelau           │ TKL     │ Oceania │ Polynesia  │ NULL                │\n",
       "│ Tonga             │ TON     │ Oceania │ Polynesia  │ NULL                │\n",
       "│ Tuvalu            │ TUV     │ Oceania │ Polynesia  │ NULL                │\n",
       "│ Wallis and Futuna │ WLF     │ Oceania │ Polynesia  │ NULL                │\n",
       "├───────────────────┴─────────┴─────────┴────────────┴─────────────────────┤\n",
       "│ 10 rows                                                        5 columns │\n",
       "└──────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation = con.sql('''\n",
    "        SELECT  *\n",
    "            FROM\n",
    "                'countries.csv'\n",
    "            WHERE\n",
    "                region = 'Oceania'\n",
    "                AND \"sub-region\" = 'Polynesia'\n",
    "''')\n",
    "relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are known as DuckDB relation objects. We can display all data in these `relations`, as demonstrated above of extract them as a list of tuples using `fetchall` method of these relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'duckdb.duckdb.DuckDBPyRelation'>\n"
     ]
    }
   ],
   "source": [
    "print(type(relation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('American Samoa', 'ASM', 'Oceania', 'Polynesia', None),\n",
       " ('Cook Islands', 'COK', 'Oceania', 'Polynesia', None),\n",
       " ('French Polynesia', 'PYF', 'Oceania', 'Polynesia', None),\n",
       " ('Niue', 'NIU', 'Oceania', 'Polynesia', None),\n",
       " ('Pitcairn', 'PCN', 'Oceania', 'Polynesia', None),\n",
       " ('Samoa', 'WSM', 'Oceania', 'Polynesia', None),\n",
       " ('Tokelau', 'TKL', 'Oceania', 'Polynesia', None),\n",
       " ('Tonga', 'TON', 'Oceania', 'Polynesia', None),\n",
       " ('Tuvalu', 'TUV', 'Oceania', 'Polynesia', None),\n",
       " ('Wallis and Futuna', 'WLF', 'Oceania', 'Polynesia', None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating with Pandas\n",
    "\n",
    "One of DuckDB’s most powerful features is its compatibility with `Pandas`. You can run SQL queries directly on Pandas DataFrames or convert query results into DataFrames.\n",
    "\n",
    "Example: Converting to Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>code</th>\n",
       "      <th>region</th>\n",
       "      <th>sub-region</th>\n",
       "      <th>intermediate-region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>ASM</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cook Islands</td>\n",
       "      <td>COK</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>French Polynesia</td>\n",
       "      <td>PYF</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Niue</td>\n",
       "      <td>NIU</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pitcairn</td>\n",
       "      <td>PCN</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samoa</td>\n",
       "      <td>WSM</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tokelau</td>\n",
       "      <td>TKL</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tonga</td>\n",
       "      <td>TON</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>TUV</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wallis and Futuna</td>\n",
       "      <td>WLF</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name code   region sub-region intermediate-region\n",
       "0     American Samoa  ASM  Oceania  Polynesia                None\n",
       "1       Cook Islands  COK  Oceania  Polynesia                None\n",
       "2   French Polynesia  PYF  Oceania  Polynesia                None\n",
       "3               Niue  NIU  Oceania  Polynesia                None\n",
       "4           Pitcairn  PCN  Oceania  Polynesia                None\n",
       "5              Samoa  WSM  Oceania  Polynesia                None\n",
       "6            Tokelau  TKL  Oceania  Polynesia                None\n",
       "7              Tonga  TON  Oceania  Polynesia                None\n",
       "8             Tuvalu  TUV  Oceania  Polynesia                None\n",
       "9  Wallis and Futuna  WLF  Oceania  Polynesia                None"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Querying Pandas DataFrames directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────┬──────────┬───────┬──────────┐\n",
       "│  id   │   name   │  age  │  salary  │\n",
       "│ int32 │ varchar  │ int32 │  double  │\n",
       "├───────┼──────────┼───────┼──────────┤\n",
       "│     1 │ Person 1 │    30 │  70000.0 │\n",
       "│     2 │ Person 2 │    25 │  55000.0 │\n",
       "│     3 │ Person 3 │    35 │  80000.0 │\n",
       "│     4 │ Person 4 │    45 │ 100000.0 │\n",
       "│     5 │ Person 5 │    40 │  85000.0 │\n",
       "│     6 │ Person 6 │    35 │  75000.0 │\n",
       "└───────┴──────────┴───────┴──────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'id': [4, 5, 6],\n",
    "    'name': ['Person 4', 'Person 5', 'Person 6'],\n",
    "    'age': [45, 40, 35],\n",
    "    'salary': [100000, 85000, 75000]\n",
    "})\n",
    "\n",
    "con.sql('''\n",
    "        INSERT INTO employees (id, name, age, salary)\n",
    "        SELECT * FROM df\n",
    "''')\n",
    "\n",
    "con.sql('select * from employees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you saw, DuckDB allows you to run SQL queries directly on a Pandas DataFrame. And as you would have guessed, you can convert query results back into DataFrames using .df()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Person 4</td>\n",
       "      <td>45</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Person 5</td>\n",
       "      <td>40</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Person 6</td>\n",
       "      <td>35</td>\n",
       "      <td>75000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      name  age  salary\n",
       "0   4  Person 4   45  100000\n",
       "1   5  Person 5   40   85000\n",
       "2   6  Person 6   35   75000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql('SELECT * FROM df').df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Parquet and Arrow\n",
    "\n",
    "DuckDB also supports efficient handling of Parquet and Arrow formats, commonly used in big data scenarios. You can read data from Parquet files and run SQL queries on them without first loading them into memory.\n",
    "\n",
    "Example: Reading from Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>code</th>\n",
       "      <th>region</th>\n",
       "      <th>sub-region</th>\n",
       "      <th>intermediate-region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>ALA</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Northern Europe</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>ASM</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name code   region       sub-region intermediate-region\n",
       "0     Afghanistan  AFG     Asia    Southern Asia                None\n",
       "1   Åland Islands  ALA   Europe  Northern Europe                None\n",
       "2         Albania  ALB   Europe  Southern Europe                None\n",
       "3         Algeria  DZA   Africa  Northern Africa                None\n",
       "4  American Samoa  ASM  Oceania        Polynesia                None"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from a Parquet file\n",
    "con.sql(\"SELECT * FROM 'countries.parquet'\").df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, DuckDB integrates well with Apache Arrow and supports operations on Arrow tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Queries and Using DuckDB for Analytical Workloads\n",
    "\n",
    "DuckDB is optimized for performance, especially for analytical queries. DuckDB's architecture, particularly its use of vectorized execution and columnar storage, helps DuckDB to speed up query processing and make it extremely efficient for data analytics. Additionally, DuckDB can operate directly on compressed data formats like Parquet, reducing the need for data decompression.\n",
    "\n",
    "- Window Functions: You can perform windowing operations (e.g., running totals, moving averages).\n",
    "- Group By: Complex group-by operations with large datasets are optimized.\n",
    "- Parallel Execution: DuckDB automatically parallelizes many operations for faster results on large datasets.\n",
    "\n",
    "\n",
    "Example: Group and count countries by their regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────┬────────────────┐\n",
       "│  region  │ country_counts │\n",
       "│ varchar  │     int64      │\n",
       "├──────────┼────────────────┤\n",
       "│ Africa   │             60 │\n",
       "│ Americas │             57 │\n",
       "│ Europe   │             51 │\n",
       "│ Asia     │             51 │\n",
       "│ Oceania  │             29 │\n",
       "│ NULL     │              1 │\n",
       "└──────────┴────────────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql('''\n",
    "        SELECT  region\n",
    "                , COUNT(DISTINCT country) AS country_counts\n",
    "            FROM\n",
    "                countries\n",
    "            GROUP BY\n",
    "                region\n",
    "            ORDER BY\n",
    "                country_counts DESC\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Calculate the average salary and find people with above avg salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────┬──────────┬───────┬──────────┐\n",
       "│  id   │   name   │  age  │  salary  │\n",
       "│ int32 │ varchar  │ int32 │  double  │\n",
       "├───────┼──────────┼───────┼──────────┤\n",
       "│     3 │ Person 3 │    35 │  80000.0 │\n",
       "│     4 │ Person 4 │    45 │ 100000.0 │\n",
       "│     5 │ Person 5 │    40 │  85000.0 │\n",
       "└───────┴──────────┴───────┴──────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "con.sql('''\n",
    "        WITH avg_salary AS (\n",
    "            SELECT\n",
    "                    ROUND(AVG(salary),2) AS avg_salary\n",
    "                FROM\n",
    "                    employees\n",
    "            )\n",
    "        \n",
    "        SELECT\n",
    "                *\n",
    "            FROM\n",
    "                employees\n",
    "            WHERE\n",
    "                salary > (SELECT avg_salary FROM avg_salary)\n",
    "        \n",
    "''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed Comparison: DuckDB vs Pandas\n",
    "\n",
    "DuckDB and Pandas are both popular tools for data manipulation in Python, but they have different strengths. Pandas is a general-purpose data manipulation library optimized for in-memory operations, whereas DuckDB is designed specifically for high-performance, analytical queries on large datasets using SQL. DuckDB's columnar storage and query optimization techniques make it significantly faster than Pandas for complex and large-scale analytical queries.\n",
    "\n",
    "### Why is DuckDB Faster for Analytical Queries?\n",
    "- *Columnar Storage:* DuckDB stores data in a columnar format, which is more efficient for analytical queries (like filtering and aggregations). Pandas stores data in row-major format, which is better for general-purpose operations but can be slower for these specific tasks.\n",
    "\n",
    "- *Query Optimization:* DuckDB uses query optimizations like predicate pushdown, efficient joins, and parallel query execution, which are typically missing or less efficient in Pandas.\n",
    "\n",
    "- *Parallel Execution:* DuckDB can automatically parallelize complex queries, leveraging multiple cores in modern CPUs, while Pandas processes data mostly single-threaded by default.\n",
    "\n",
    "- *On-Disk Storage:* DuckDB efficiently handles datasets that don’t fit into memory by using on-disk storage formats like Parquet, while Pandas requires that all data fits into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas filtering time: 0.93 seconds\n",
      "DuckDB filtering time: 0.60 seconds\n",
      "DuckDB is 1.55 times faster than Pandas\n"
     ]
    }
   ],
   "source": [
    "import duckdb as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Generate a large random dataset\n",
    "data_size = 10**8  # 10 million rows\n",
    "df = pd.DataFrame({\n",
    "    'id': np.arange(data_size),\n",
    "    'value': np.random.randn(data_size)\n",
    "})\n",
    "\n",
    "# Scenario: Filter rows where value is greater than 1\n",
    "\n",
    "# Filtering using Pandas\n",
    "start = time.time()\n",
    "pandas_filtered = df[df['value'] > 1]\n",
    "end = time.time()\n",
    "pandas_time = end - start\n",
    "print(f\"Pandas filtering time: {pandas_time:.2f} seconds\")\n",
    "\n",
    "# Filtering using DuckDB\n",
    "start = time.time()\n",
    "duckdb_filtered = dd.query(\"SELECT * FROM df WHERE value > 1\").df()\n",
    "end = time.time()\n",
    "duckdb_time = end - start\n",
    "print(f\"DuckDB filtering time: {duckdb_time:.2f} seconds\")\n",
    "\n",
    "print(f\"DuckDB is {pandas_time / duckdb_time:.2f} times faster than Pandas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas filtering time: 0.54 seconds\n",
      "DuckDB aggregation time: 0.10 seconds\n",
      "DuckDB is 5.27 times faster than Pandas\n"
     ]
    }
   ],
   "source": [
    "# Scenario: Calculate mean of 'value' column\n",
    "\n",
    "# Aggregating using Pandas\n",
    "start = time.time()\n",
    "pandas_mean = df['value'].mean()\n",
    "end = time.time()\n",
    "pandas_time = end - start\n",
    "print(f\"Pandas filtering time: {pandas_time:.2f} seconds\")\n",
    "\n",
    "# Aggregating using DuckDB\n",
    "start = time.time()\n",
    "duckdb_mean = dd.query(\"SELECT AVG(value) FROM df\").fetchone()[0]\n",
    "end = time.time()\n",
    "duckdb_time = end - start\n",
    "print(f\"DuckDB aggregation time: {duckdb_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "print(f\"DuckDB is {pandas_time / duckdb_time:.2f} times faster than Pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing the Connection\n",
    "\n",
    "Once you're done with your queries, always remember to close the DuckDB connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "DuckDB is a powerful tool for performing efficient SQL operations in Python, especially when working with large datasets or complex analytical queries. Its ease of integration with modern data formats like Pandas, Parquet, and Arrow, combined with its fast performance, makes it a valuable addition to any data analyst's toolkit.\n",
    "\n",
    "Whether you're building an in-memory database for fast analytics, working with small datasets or working with large-scale data in Parquet files, DuckDB can simplify the process and accelerate performance. Its SQL syntax is easy to learn, and its compatibility with Python makes it highly flexible for a wide range of data-related tasks.\n",
    "\n",
    "Read more at [DuckDB Python API](https://duckdb.org/docs/api/python/overview):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
