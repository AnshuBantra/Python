{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Tree-Based Models in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your first classification tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this exercise you'll work with the Wisconsin Breast Cancer Dataset from the UCI machine learning repository. You'll predict whether a tumor is malignant or benign based on two features: the mean radius of the tumor (radius_mean) and its mean number of concave points (concave points_mean).\n",
    "\n",
    "The dataset is already loaded in your workspace and is split into 80% train and 20% test. The feature matrices are assigned to X_train and X_test, while the arrays of labels are assigned to y_train and y_test where class 1 corresponds to a malignant tumor and class 0 corresponds to a benign tumor. To obtain reproducible results, we also defined a variable called SEED which is set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_wbc = pd.read_csv(r'.\\data\\wbc.csv')\n",
    "df_wbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_wbc[['radius_mean', 'concave points_mean']]\n",
    "y = pd.Series([0 if _=='B' else 1 for _ in df_wbc[['diagnosis']].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree as sktr\n",
    "import sklearn.model_selection as skms\n",
    "import sklearn.metrics as skme\n",
    "\n",
    "X_train, X_test, y_train, y_test = skms.train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6\n",
    "dtc = sktr.DecisionTreeClassifier(max_depth=6, random_state=1)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dtc.predict(X_test)\n",
    "print(y_pred[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the classification tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Compute test set accuracy  \n",
    "acc = skme.accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy: {:.2f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression vs classification tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A classification tree divides the feature space into rectangular regions. In contrast, a linear model such as logistic regression produces only a single linear decision boundary dividing the feature space into two decision regions.\n",
    "\n",
    "We have written a custom function called plot_labeled_decision_regions() that you can use to plot the decision regions of a list containing two trained classifiers. You can type help(plot_labeled_decision_regions) in the IPython shell to learn more about this function.\n",
    "\n",
    "X_train, X_test, y_train, y_test, the model dt that you've trained in an earlier exercise , as well as the function plot_labeled_decision_regions() are available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (1326040239.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    markers=\\'s^oxv<>\\',\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "def plot_decision_regions(  X, y, clf,\n",
    "                            feature_index=None,\n",
    "                            filler_feature_values=None,\n",
    "                            filler_feature_ranges=None,\n",
    "                            ax=None,\n",
    "                            X_highlight=None,\n",
    "                            zoom_factor=1.,\n",
    "                            legend=1,\n",
    "                            hide_spines=True,\n",
    "                            markers=\\'s^oxv<>\\',\n",
    "                            colors=(\\'#1f77b4,#ff7f0e,#3ca02c,#d62728,\\'\n",
    "                                    \\'#9467bd,#8c564b,#e377c2,\\'\n",
    "                                    \\'#7f7f7f,#bcbd22,#17becf\\'),\n",
    "                            scatter_kwargs=None,\n",
    "                            contourf_kwargs=None,\n",
    "                            scatter_highlight_kwargs=None):\n",
    "    \"\"\" Plot decision regions of a classifier.\n",
    "    \n",
    "        Please note that this functions assumes that class labels are\n",
    "        labeled consecutively, e.g,. 0, 1, 2, 3, 4, and 5. If you have class\n",
    "        labels with integer labels > 4, you may want to provide additional colors\n",
    "        and/or markers as `colors` and `markers` arguments.\n",
    "        See http://matplotlib.org/examples/color/named_colors.html for more information.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "        Feature Matrix.\n",
    "        \n",
    "        y : array-like, shape = [n_samples]\n",
    "        True class labels.\n",
    "        \n",
    "        clf : Classifier object.\n",
    "        Must have a .predict method.\n",
    "        \n",
    "        feature_index : array-like (default: (0,) for 1D, (0, 1) otherwise)\n",
    "        Feature indices to use for plotting. The first index in\n",
    "        `feature_index` will be on the x-axis, the second index will be\n",
    "        on the y-axis.\\n\\n    filler_feature_values : dict (default: None)\n",
    "        Only needed for number features > 2. Dictionary of feature\n",
    "        index-value pairs for the features not being plotted.\n",
    "        \n",
    "        filler_feature_ranges : dict (default: None)\n",
    "        Only needed for number features > 2. Dictionary of feature\n",
    "        index-value pairs for the features not being plotted. Will use the\n",
    "        ranges provided to select training samples for plotting.\n",
    "        \n",
    "        ax : matplotlib.axes.Axes (default: None)\n",
    "        An existing matplotlib Axes. Creates\n",
    "        one if ax=None.\n",
    "        \n",
    "        X_highlight : array-like, shape = [n_samples, n_features] (default: None)\n",
    "        An array with data points that are used to highlight samples in `X`.\n",
    "        \n",
    "        zoom_factor : float (default: 1.0)\n",
    "        Controls the scale of the x- and y-axis of the decision plot.\n",
    "        \n",
    "        hide_spines : bool (default: True)\n",
    "        Hide axis spines if True.\n",
    "        \n",
    "        legend : int (default: 1)\n",
    "        Integer to specify the legend location.\n",
    "        No legend if legend is 0.\n",
    "        \n",
    "        markers : str (default: \\'s^oxv<>\\')\n",
    "        Scatterplot markers.\n",
    "        \n",
    "        colors : str (default: \\'red,blue,limegreen,gray,cyan\\')\n",
    "        Comma separated list of colors.\n",
    "        \n",
    "        scatter_kwargs : dict (default: None)\n",
    "        Keyword arguments for underlying matplotlib scatter function.\n",
    "        \n",
    "        contourf_kwargs : dict (default: None)\n",
    "        Keyword arguments for underlying matplotlib contourf function.\n",
    "        \n",
    "        scatter_highlight_kwargs : dict (default: None)\n",
    "        Keyword arguments for underlying matplotlib scatter function.\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        ax : matplotlib.axes.Axes object\n",
    "        \n",
    "        Examples\n",
    "        -----------\n",
    "        For usage examples, please see\n",
    "        http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/\n",
    "    \"\"\"\n",
    "        check_Xy(X, y, y_int=True)  # Validate X and y arrays\n",
    "        dim = X.shape[1]\n",
    "        \n",
    "        if ax is None:\n",
    "            ax = plt.gca()\n",
    "            plot_testdata = True\n",
    "            if not isinstance(X_highlight, np.ndarray):\n",
    "                if X_highlight is not None:\n",
    "                    raise ValueError(\\'X_highlight must be a NumPy array or None\\')\n",
    "                else:\n",
    "                    plot_testdata = False\n",
    "            elif len(X_highlight.shape) < 2:\n",
    "                raise ValueError(\\'X_highlight must be a 2D array\\')\n",
    "            if feature_index is not None:\n",
    "                # Unpack and validate the feature_index values\n",
    "                if dim == 1:\n",
    "                    raise ValueError('feature_index requires more than one training feature\\')\n",
    "                    try:\n",
    "                        x_index, y_index = feature_index\n",
    "                    except ValueError:\n",
    "                        raise ValueError('Unable to unpack feature_index. Make sure feature_index only has two dimensions.\\')\n",
    "                    try:\n",
    "                        X[:, x_index], X[:, y_index]\n",
    "                    except IndexError:\n",
    "                        raise IndexError('feature_index values out of range. X.shape is {}, but feature_index is {}\\'.format(X.shape, feature_index))\n",
    "                else:\n",
    "                    feature_index = (0, 1)\n",
    "                    x_index, y_index = feature_index # Extra input validation for higher number of training features\n",
    "                if dim > 2:\n",
    "                    if filler_feature_values is None:\n",
    "                        raise ValueError('Filler values must be provided when X has more than 2 training features.')\n",
    "                    if filler_feature_ranges is not None:\n",
    "                        if not set(filler_feature_values) == set(filler_feature_ranges):\n",
    "                            raise ValueError('filler_feature_values and filler_feature_ranges must have the same keys')\n",
    "                            \n",
    "                    # Check that all columns in X are accounted for\n",
    "                    column_check = np.zeros(dim, dtype=bool)\n",
    "                    for idx in filler_feature_values:\n",
    "                        column_check[idx] = True\n",
    "                        for idx in feature_index:\n",
    "                            column_check[idx] = True\n",
    "                            if not all(column_check):\n",
    "                                missing_cols = np.argwhere(~column_check).flatten()\n",
    "                                raise ValueError('Column(s) {} need to be accounted for in either feature_index or filler_feature_values'.format(missing_cols))\n",
    "                    marker_gen = cycle(list(markers))\n",
    "                    n_classes = np.unique(y).shape[0]\n",
    "                    colors = colors.split(\\',\\')\n",
    "                    colors_gen = cycle(colors)\n",
    "                    colors = [next(colors_gen for c in range(n_classes)]\n",
    "                    # Get minimum and maximum \n",
    "                    x_min, x_max = (X[:, x_index].min() - 1./zoom_factor,\n",
    "                                    X[:, x_index].max() + 1./zoom_factor)\n",
    "                    if dim == 1:\n",
    "                        y_min, y_max = -1, 1\n",
    "                    else:\n",
    "                        y_min, y_max = (X[:, y_index].min() - 1./zoom_factor,\n",
    "                                        X[:, y_index].max() + 1./zoom_factor)\n",
    "                                        \n",
    "                    xnum, ynum = plt.gcf().dpi * plt.gcf().get_size_inches()\n",
    "                    xnum, ynum = floor(xnum), ceil(ynum)\n",
    "                    xx, yy = np.meshgrid(np.linspace(x_min, x_max, num=xnum),\n",
    "                    np.linspace(y_min, y_max, num=ynum))\n",
    "                    \n",
    "                    if dim == 1:\n",
    "                        X_predict = np.array([xx.ravel()]).T\n",
    "                    else:\n",
    "                        X_grid = np.array([xx.ravel(), yy.ravel()]).T\n",
    "                        X_predict = np.zeros((X_grid.shape[0], dim))\n",
    "                        X_predict[:, x_index] = X_grid[:, 0]\n",
    "                        X_predict[:, y_index] = X_grid[:, 1]\n",
    "                    if dim > 2:\n",
    "                        for feature_idx in filler_feature_values:\n",
    "                            X_predict[:, feature_idx] = filler_feature_values[feature_idx]\n",
    "                            Z = clf.predict(X_predict.astype(X.dtype))\n",
    "                            Z = Z.reshape(xx.shape)\n",
    "                            # Plot decisoin region\n",
    "                            # Make sure contourf_kwargs has backwards compatible defaults\n",
    "                            contourf_kwargs_default = {\\'alpha\\': 0.45, \\'antialiased\\': True}\n",
    "                            contourf_kwargs = format_kwarg_dictionaries(\n",
    "                                default_kwargs=contourf_kwargs_default,\n",
    "                                user_kwargs=contourf_kwargs,\n",
    "                                protected_keys=[\\'colors\\', \\'levels\\'])\n",
    "                            cset = ax.contourf( xx, yy, Z,\n",
    "                                                colors=colors,\n",
    "                                                levels=np.arange(Z.max() + 2) - 0.5,\n",
    "                                                **contourf_kwargs)\n",
    "                            ax.contour( xx, yy, Z, cset.levels,\n",
    "                                        colors='k\\',\n",
    "                                        linewidths=0.5,\n",
    "                                        antialiased=True)\n",
    "                            ax.axis([xx.min(), xx.max(), yy.min(), yy.max()])\n",
    "                            # Scatter training data samples\n",
    "                            # Make sure scatter_kwargs has backwards compatible defaults\n",
    "                            scatter_kwargs_default = {\\'alpha\\': 0.8, \\'edgecolor\\': \\'black\\'}\n",
    "                            scatter_kwargs = format_kwarg_dictionaries(\n",
    "                                    default_kwargs=scatter_kwargs_default,\n",
    "                                    user_kwargs=scatter_kwargs,\n",
    "                                    protected_keys=[\\'c\\', \\'marker\\', \\'label\\'])\n",
    "                            for idx, c in enumerate(np.unique(y)):\\n        if dim == 1:\\n            y_data = [0 for i in X[y == c]]\\n            x_data = X[y == c]\\n        elif dim == 2:\\n            y_data = X[y == c, y_index]\\n            x_data = X[y == c, x_index]\\n        elif dim > 2 and filler_feature_ranges is not None:\\n            class_mask = y == c\\n            feature_range_mask = get_feature_range_mask(\\n                            X, filler_feature_values=filler_feature_values,\\n                            filler_feature_ranges=filler_feature_ranges)\\n            y_data = X[class_mask & feature_range_mask, y_index]\\n            x_data = X[class_mask & feature_range_mask, x_index]\\n        else:\\n            continue\\n\\n        ax.scatter(x=x_data,\\n                   y=y_data,\\n                   c=colors[idx],\\n                   marker=next(marker_gen),\\n                   label=c,\\n                   **scatter_kwargs)\\n\\n    if hide_spines:\\n        ax.spines[\\'right\\'].set_visible(False)\\n        ax.spines[\\'top\\'].set_visible(False)\\n        ax.spines[\\'left\\'].set_visible(False)\\n        ax.spines[\\'bottom\\'].set_visible(False)\\n    ax.yaxis.set_ticks_position(\\'left\\')\\n    ax.xaxis.set_ticks_position(\\'bottom\\')\\n    if dim == 1:\\n        ax.axes.get_yaxis().set_ticks([])\\n\\n    if plot_testdata:\\n        if dim == 1:\\n            x_data = X_highlight\\n            y_data = [0 for i in X_highlight]\\n        elif dim == 2:\\n            x_data = X_highlight[:, x_index]\\n            y_data = X_highlight[:, y_index]\\n        else:\\n            feature_range_mask = get_feature_range_mask(\\n                    X_highlight, filler_feature_values=filler_feature_values,\\n                    filler_feature_ranges=filler_feature_ranges)\\n            y_data = X_highlight[feature_range_mask, y_index]\\n            x_data = X_highlight[feature_range_mask, x_index]\\n\\n        # Make sure scatter_highlight_kwargs backwards compatible defaults\\n        scatter_highlight_defaults = {\\'c\\': \\'none\\',\\n                                      \\'edgecolor\\': \\'black\\',\\n                                      \\'alpha\\': 1.0,\\n                                      \\'linewidths\\': 1,\\n                                      \\'marker\\': \\'o\\',\\n                                      \\'s\\': 80}\\n        scatter_highlight_kwargs = format_kwarg_dictionaries(\\n                                    default_kwargs=scatter_highlight_defaults,\\n                                    user_kwargs=scatter_highlight_kwargs)\\n        ax.scatter(x_data,\\n                   y_data,\\n                   **scatter_highlight_kwargs)\\n\\n    if legend:\\n        if dim > 2 and filler_feature_ranges is None:\\n            pass\\n        else:\\n            handles, labels = ax.get_legend_handles_labels()\\n            ax.legend(handles, labels,\\n                      framealpha=0.3, scatterpoints=1, loc=legend)\\n\\n    return ax\\n'\n",
    "\n",
    "def plot_labeled_decision_regions(X,y, models):\n",
    "    ''' Function producing a scatter plot of the instances contained\n",
    "        in the 2D dataset (X,y) along with the decision\n",
    "        regions of two trained classification models contained in the\n",
    "        list 'models'.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: pandas DataFrame corresponding to two numerical features\n",
    "        y: pandas Series corresponding the class labels\n",
    "        models: list containing two trained classifiers\n",
    "    '''\n",
    "    if len(models) != 2:\n",
    "        raise Exception('''\\n        Models should be a list containing only two trained classifiers.\\n        ''')\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        raise Exception('''\\n        X has to be a pandas DataFrame with two numerical features.\\n        ''')\n",
    "    if not isinstance(y, pd.Series):\n",
    "        raise Exception('''\\n        y has to be a pandas Series corresponding to the labels.\\n        ''')\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(6.0,2.7), sharey=True)\n",
    "    for i, model in enumerate(models):\n",
    "        plot_decision_regions(X.values,y.values, model, legend= 2, ax = ax[i])\n",
    "        ax[i].set_title(model.__class__.__name__)\n",
    "        ax[i].set_xlabel(X.columns[0])\n",
    "        if i == 0:\n",
    "            ax[i].set_ylabel(X.columns[1])\n",
    "            ax[i].set_ylim(X.values[:,1].min(), X.values[:,1].max())\n",
    "            ax[i].set_xlim(X.values[:,0].min(), X.values[:,0].max())\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_decision_regions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m clfs \u001b[38;5;241m=\u001b[39m [logreg, dtc]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Review the decision regions of the two classifiers\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mplot_labeled_decision_regions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 21\u001b[0m, in \u001b[0;36mplot_labeled_decision_regions\u001b[1;34m(X, y, models)\u001b[0m\n\u001b[0;32m     19\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6.0\u001b[39m,\u001b[38;5;241m2.7\u001b[39m), sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models):\n\u001b[1;32m---> 21\u001b[0m     \u001b[43mplot_decision_regions\u001b[49m(X\u001b[38;5;241m.\u001b[39mvalues,y\u001b[38;5;241m.\u001b[39mvalues, model, legend\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, ax \u001b[38;5;241m=\u001b[39m ax[i])\n\u001b[0;32m     22\u001b[0m     ax[i]\u001b[38;5;241m.\u001b[39mset_title(model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     23\u001b[0m     ax[i]\u001b[38;5;241m.\u001b[39mset_xlabel(X\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_decision_regions' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x270 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import LogisticRegression from sklearn.linear_model\n",
    "import sklearn.linear_model as sklm #import  LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Instatiate logreg\n",
    "logreg = sklm.LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit logreg to the training set\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Define a list called clfs containing the two classifiers logreg and dt\n",
    "clfs = [logreg, dtc]\n",
    "\n",
    "# Review the decision regions of the two classifiers\n",
    "plot_labeled_decision_regions(X_test, y_test, clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification tree Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "B    357\n",
       "M    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wbc['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier from sklearn.tree\n",
    "import sklearn.tree as sktr #import DecisionTreeClassifier\n",
    "\n",
    "# Import train_test_split\n",
    "import sklearn.model_selection as skms #import train_test_split\n",
    "\n",
    "# Import accuracy_score\n",
    "import sklearn.metrics as skme # import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_wbc[[\n",
    "  'radius_mean',\n",
    "  'texture_mean',\n",
    "  'perimeter_mean',\n",
    "  'area_mean',\n",
    "  'smoothness_mean',\n",
    "  'compactness_mean',\n",
    "  'concavity_mean',\n",
    "  'concave points_mean',\n",
    "  'symmetry_mean',\n",
    "  'fractal_dimension_mean',\n",
    "  'radius_se',\n",
    "  'texture_se',\n",
    "  'perimeter_se',\n",
    "  'area_se',\n",
    "  'smoothness_se',\n",
    "  'compactness_se',\n",
    "  'concavity_se',\n",
    "  'concave points_se',\n",
    "  'symmetry_se',\n",
    "  'fractal_dimension_se',\n",
    "  'radius_worst',\n",
    "  'texture_worst',\n",
    "  'perimeter_worst',\n",
    "  'area_worst',\n",
    "  'smoothness_worst',\n",
    "  'compactness_worst',\n",
    "  'concavity_worst',\n",
    "  'concave points_worst',\n",
    "  'symmetry_worst',\n",
    "  'fractal_dimension_worst'\n",
    "]]\n",
    "\n",
    "y = [1 if _=='M' else '0' for _ in df_wbc['diagnosis']]\n",
    "\n",
    "# Split dataset into 80% train, 20%\n",
    "testX_train, X_test, y_train, y_test= skms.train_test_split(\n",
    "  X, y,\n",
    "  test_size=0.2,\n",
    "  stratify=y,\n",
    "  random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=8, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=8, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=8, random_state=1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_entropy = sktr.DecisionTreeClassifier(\n",
    "    max_depth=8,\n",
    "    criterion='entropy',\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_entropy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = dt_entropy.predict(X_test)\n",
    "# accuracy_entropy = skme.accuracy_score(y_test, y_pred)\n",
    "# accuracy_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnose bias and variance problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\anshu\\OneDrive\\Teaching Opportunities\\Excel\\Challenges\\Excel_Challenge_504 - US Presidents All First Chars Same.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(path, sheet_name='Sheet1', usecols='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US Presidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thomas Jefferson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James Monroe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       US Presidents\n",
       "0  George Washington\n",
       "1         John Adams\n",
       "2   Thomas Jefferson\n",
       "3      James Madison\n",
       "4       James Monroe"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'US Presidents': ['George Geoff', 'Tim Terry', 'Ron Berry', 'John Jerry Terry']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial(name):\n",
    "    parts = name.lower().split()\n",
    "    if len(parts) > 1:\n",
    "        first_char = parts[0][0]\n",
    "        initials = ''.join([part[0] for part in parts[1:]])\n",
    "    #     return first_char in initials\n",
    "    # return False\n",
    "    return (parts, first_char, (initials), first_char in initials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['george', 'geoff'], 'g', 'g', True)\n",
      "(['tim', 'terry'], 't', 't', True)\n",
      "(['ron', 'berry'], 'r', 'b', False)\n",
      "(['john', 'jerry', 'terry'], 'j', 'jt', True)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(len(df)):\n",
    "    print(get_initial(df.iloc[_,0])) #.str.lower().values[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_matching_initial(name):\n",
    "    parts = name.lower().split()\n",
    "    if len(parts) > 1:\n",
    "        first_char = parts[0][0]\n",
    "        initials = ''.join([part[0] for part in parts[1:]])\n",
    "        return first_char in initials\n",
    "    return False\n",
    "\n",
    "# df = xl(\"A1:A47\", headers=True)\n",
    "df['matching'] = df['US Presidents'].apply(has_matching_initial)\n",
    "df[df['matching']]['US Presidents'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             names  matching_initial\n",
      "1    Attr Atub Art              True\n",
      "3  Charlie C. Chor              True\n",
      "4    David D. Door              True\n",
      "6         Frank F.              True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'names': ['Alice B.', 'Attr Atub Art', 'Bob B. Charlie', 'Charlie C. Chor', 'David D. Door', 'Eve E. First', 'Frank F.']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def has_matching_initial(name):\n",
    "    parts = name.lower().split()\n",
    "    if len(parts) > 1:\n",
    "        # first_char = parts[0][0]\n",
    "        initials = ''.join([part[0] for part in parts])\n",
    "        # return initials.count(first_char)==len(initials)\n",
    "        # print (f'First Char {initials[0]}, Length of initials {initials}, {initials.count(initials[0])==len(initials)}')\n",
    "        return initials.count(initials[0])==len(initials)\n",
    "    return False\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['matching_initial'] = df['names'].apply(has_matching_initial)\n",
    "\n",
    "# Filter the DataFrame to get names with matching initials\n",
    "matching_names = df[df['matching_initial']]#['names'].values\n",
    "\n",
    "print(matching_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | names           | matching_initial   |\n",
      "|---:|:----------------|:-------------------|\n",
      "|  1 | Attr Atub Art   | True               |\n",
      "|  3 | Charlie C. Chor | True               |\n",
      "|  4 | David D. Door   | True               |\n",
      "|  6 | Frank F.        | True               |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'names': ['Alice B.', 'Attr Atub Art', 'Bob B. Charlie', 'Charlie C. Chor', 'David D. Door', 'Eve E. First', 'Frank F.']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def has_matching_initial(name):\n",
    "    parts = name.lower().split()\n",
    "    if len(parts) > 1:\n",
    "        initials = ''.join([part[0] for part in parts])\n",
    "        return initials.count(initials[0])==len(initials)\n",
    "    return False\n",
    "\n",
    "df['matching_initial'] = df['names'].apply(has_matching_initial)\n",
    "matching_names = df[df['matching_initial']]#['names'].values\n",
    "print(matching_names.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "chars_ = string.ascii_uppercase\n",
    "start_ = 0\n",
    "line_ = ''\n",
    "lst_ = []\n",
    "for _ in range(8):\n",
    "  line_ = f\"{(' '.join(chars_[start_:start_+_])):^11}\"\n",
    "  if line_.split():\n",
    "    lst_.append(re.split('( )', line_))#.split((' ')))\n",
    "  start_ += _"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
