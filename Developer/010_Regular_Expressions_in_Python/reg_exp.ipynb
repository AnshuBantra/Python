{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expressions in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to String Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chanracters in the review:  52\n"
     ]
    }
   ],
   "source": [
    "review = 'This was a great movie. I can watch it again anytime'\n",
    "length_string = len(review)\n",
    "to_string = str(length_string)\n",
    "statement = 'Number of chanracters in the review: '\n",
    "print(statement+' '+to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "Number of characters in this review: 135\n"
     ]
    }
   ],
   "source": [
    "movie = 'fox and kelley soon become bitter rivals because the new fox books store is opening up right across the block from the small business .'\n",
    "length_string = len(movie)\n",
    "print(length_string)\n",
    "# Find characters in movie variable\n",
    "length_string = len(movie)\n",
    "# Convert to string\n",
    "to_string = str(length_string)\n",
    "# Predefined variable\n",
    "statement = \"Number of characters in this review:\"\n",
    "# Concatenate strings and print result\n",
    "print(statement+' '+to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the most significant tension of _rushmore_ is the potential relationship between a teacher and his student .\n",
      "the most significant tension of _rushmore_ is the potential relationship between a teacher and his student .\n"
     ]
    }
   ],
   "source": [
    "movie1 = 'the most significant tension of _election_ is the potential relationship between a teacher and his student .'\n",
    "movie2 = 'the most significant tension of _rushmore_ is the potential relationship between a teacher and his student .'\n",
    "# Select the first 32 characters of movie1\n",
    "first_part = movie1[:32]\n",
    "# Select from 43rd character to the end of movie1\n",
    "last_part = movie1[42:]\n",
    "# Select from 33rd to the 42nd character of movie2\n",
    "middle_part = movie2[32:42]\n",
    "# Print concatenation and movie2 variable\n",
    "print(first_part+middle_part+last_part) \n",
    "print(movie2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts I stressed\n"
     ]
    }
   ],
   "source": [
    "movie = 'oh my God! desserts I stressed was an ugly movie'\n",
    "# Get the word\n",
    "movie_title = movie[11:30]\n",
    "\n",
    "# Obtain the palindrome\n",
    "palindrome = movie_title[::-1]\n",
    "\n",
    "# Print the word if it's a palindrome\n",
    "if movie_title == palindrome:\n",
    "\tprint(movie_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = \"This string will be split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'string', 'will', 'be', 'split']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'string', 'will', 'be', 'split']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.split(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'string', 'will be split']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.split(sep=' ', maxsplit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'string', 'will', 'be', 'split']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.rsplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This string will', 'be', 'split']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.rsplit(sep=' ', maxsplit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This string will', 'be split']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = \"This string will\\nbe split\"\n",
    "my_string.splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'join'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m my_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmy_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'join'"
     ]
    }
   ],
   "source": [
    "my_list = ['This', 'string', 'will', 'be', 'split']\n",
    "my_list.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This string will be split'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = '  This string will be stripped\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This string will be stripped'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  This string will be stripped'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This string will be stripped\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$i supposed that coming from mtv films i should expect no less$'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = '$I supposed that coming from MTV Films I should expect no less$'\n",
    "movie.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$i supposed that coming from mtv films i should expect no less$\n",
      "i supposed that coming from mtv films i should expect no less\n",
      "['i', 'supposed', 'that', 'coming', 'from', 'mtv', 'films', 'i', 'should', 'expect', 'no', 'less']\n",
      "s\n"
     ]
    }
   ],
   "source": [
    "# Convert to lowercase and print the result\n",
    "movie_lower = movie.lower()\n",
    "print(movie_lower)\n",
    "\n",
    "# Remove specified character and print the result\n",
    "movie_no_sign = movie_lower.strip(\"$\")\n",
    "print(movie_no_sign)\n",
    "\n",
    "# Split the string into substrings and print the result\n",
    "movie_split = movie_no_sign.split()\n",
    "print(movie_split)\n",
    "\n",
    "# Select root word and print the result\n",
    "word_root = movie_split[1][0]\n",
    "print(word_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the film,however,is all good\n",
      "['the film', 'however', 'is all good']\n",
      "the film however is all good\n"
     ]
    }
   ],
   "source": [
    "movie = 'the film,however,is all good<\\\\i>'\n",
    "# Remove tags happening at the end and print results\n",
    "movie_tag = movie.rstrip(\"<\\i>\")\n",
    "print(movie_tag)\n",
    "\n",
    "# Split the string using commas and print results\n",
    "movie_no_comma = movie_tag.split(\",\")\n",
    "print(movie_no_comma)\n",
    "\n",
    "# Join back together and print results\n",
    "movie_join = ' '.join(movie_no_comma)\n",
    "print(movie_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mtv films election, a high school comedy, is a current example', 'from there, director steven spielberg wastes no time, taking us into the water on a midnight swim']\n",
      "['mtv films election', ' a high school comedy', ' is a current example']\n",
      "['from there', ' director steven spielberg wastes no time', ' taking us into the water on a midnight swim']\n"
     ]
    }
   ],
   "source": [
    "file = 'mtv films election, a high school comedy, is a current example\\nfrom there, director steven spielberg wastes no time, taking us into the water on a midnight swim'\n",
    "\n",
    "# Split string at line boundaries\n",
    "file_split = file.splitlines()\n",
    "\n",
    "# Print file_split\n",
    "print(file_split)\n",
    "\n",
    "# Complete for-loop to split by commas\n",
    "for substring in file_split:\n",
    "    substring_split = substring.split(sep=',')\n",
    "    print(substring_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding and replacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    it's clear that he's passionate about his beli...\n",
       "1    I believe you I always said that the actor act...\n",
       "2    it's astonishing how frightening the actor act...\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "movies = pd.Series([\n",
    "    \"it's clear that he's passionate about his beliefs , and that he's not just a punk looking for an excuse to beat people up .\"\n",
    "    , 'I believe you I always said that the actor actor actor is amazing in every movie he has played'\n",
    "    , \"it's astonishing how frightening the actor actor norton looks with a shaved head and a swastika on his chest.\"\n",
    "])\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word not found\n",
      "I believe you I always said that the actor is amazing in every movie he has played\n",
      "it's astonishing how frightening the actor norton looks with a shaved head and a swastika on his chest.\n"
     ]
    }
   ],
   "source": [
    "for movie in movies:\n",
    "  \t# If actor is not found between character 37 and 41 inclusive\n",
    "    # Print word not found\n",
    "    if movie.find(\"actor\", 37, 42) == -1:\n",
    "        print(\"Word not found\")\n",
    "    # Count occurrences and replace two with one\n",
    "    elif movie.count(\"actor\") == 2:  \n",
    "        print(movie.replace(\"actor actor\", \"actor\"))\n",
    "    else:\n",
    "        # Replace three occurrences with one\n",
    "        print(movie.replace(\"actor actor actor\", \"actor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "for movie in movies:\n",
    "  # Find the first occurrence of word\n",
    "  print(movie.find('money', 12, 51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substring not found\n",
      "substring not found\n",
      "substring not found\n"
     ]
    }
   ],
   "source": [
    "for movie in movies:\n",
    "  try:\n",
    "    # Find the first occurrence of word\n",
    "  \tprint(movie.index('money', 12, 51))\n",
    "  except ValueError:\n",
    "    print(\"substring not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1270816\\AppData\\Local\\Temp\\ipykernel_20756\\4080736814.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natural Language Toolkit</td>\n",
       "      <td>suite of libraries and programs for symbolic a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TextBlob</td>\n",
       "      <td>Python library for processing textual data. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gensim</td>\n",
       "      <td>Gensim is a robust open-source vector space mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       tool                                        description\n",
       "0  Natural Language Toolkit  suite of libraries and programs for symbolic a...\n",
       "1                  TextBlob  Python library for processing textual data. It...\n",
       "2                    Gensim  Gensim is a robust open-source vector space mo..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df = pd.read_csv('./Datasets/wikipedia.csv', index_col=0)\n",
    "wiki_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Toolkit suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.\n",
      "TextBlob Python library for processing textual data. It provides a simple API for diving into common natural language processing tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
      "Gensim Gensim is a robust open-source vector space modeling and topic modeling toolkit implemented in Python. It uses NumPy, SciPy and optionally Cython for performance. Gensim is specifically designed to handle large text collections, using data streaming and efficient incremental algorithms, which differentiates it from most other scientific software packages that only target batch and in-memory processing.\n",
      "artificial intelligence In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.\n"
     ]
    }
   ],
   "source": [
    "for _ in wiki_df.itertuples():\n",
    "  print(_.tool, _.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
