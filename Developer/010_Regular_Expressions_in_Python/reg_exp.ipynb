{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expressions in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to String Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chanracters in the review:  52\n"
     ]
    }
   ],
   "source": [
    "review = 'This was a great movie. I can watch it again anytime'\n",
    "length_string = len(review)\n",
    "to_string = str(length_string)\n",
    "statement = 'Number of chanracters in the review: '\n",
    "print(statement+' '+to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "Number of characters in this review: 135\n"
     ]
    }
   ],
   "source": [
    "movie = 'fox and kelley soon become bitter rivals because the new fox books store is opening up right across the block from the small business .'\n",
    "length_string = len(movie)\n",
    "print(length_string)\n",
    "# Find characters in movie variable\n",
    "length_string = len(movie)\n",
    "# Convert to string\n",
    "to_string = str(length_string)\n",
    "# Predefined variable\n",
    "statement = \"Number of characters in this review:\"\n",
    "# Concatenate strings and print result\n",
    "print(statement+' '+to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the most significant tension of _rushmore_ is the potential relationship between a teacher and his student .\n",
      "the most significant tension of _rushmore_ is the potential relationship between a teacher and his student .\n"
     ]
    }
   ],
   "source": [
    "movie1 = 'the most significant tension of _election_ is the potential relationship between a teacher and his student .'\n",
    "movie2 = 'the most significant tension of _rushmore_ is the potential relationship between a teacher and his student .'\n",
    "# Select the first 32 characters of movie1\n",
    "first_part = movie1[:32]\n",
    "# Select from 43rd character to the end of movie1\n",
    "last_part = movie1[42:]\n",
    "# Select from 33rd to the 42nd character of movie2\n",
    "middle_part = movie2[32:42]\n",
    "# Print concatenation and movie2 variable\n",
    "print(first_part+middle_part+last_part) \n",
    "print(movie2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts I stressed\n"
     ]
    }
   ],
   "source": [
    "movie = 'oh my God! desserts I stressed was an ugly movie'\n",
    "# Get the word\n",
    "movie_title = movie[11:30]\n",
    "\n",
    "# Obtain the palindrome\n",
    "palindrome = movie_title[::-1]\n",
    "\n",
    "# Print the word if it's a palindrome\n",
    "if movie_title == palindrome:\n",
    "\tprint(movie_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = \"This string will be split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'string', 'will', 'be', 'split']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'string', 'will', 'be', 'split']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.split(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'string', 'will be split']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.split(sep=' ', maxsplit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'string', 'will', 'be', 'split']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.rsplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This string will', 'be', 'split']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.rsplit(sep=' ', maxsplit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This string will', 'be split']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = \"This string will\\nbe split\"\n",
    "my_string.splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'join'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m my_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmy_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'join'"
     ]
    }
   ],
   "source": [
    "my_list = ['This', 'string', 'will', 'be', 'split']\n",
    "my_list.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This string will be split'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = '  This string will be stripped\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This string will be stripped'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  This string will be stripped'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This string will be stripped\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$i supposed that coming from mtv films i should expect no less$'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = '$I supposed that coming from MTV Films I should expect no less$'\n",
    "movie.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$i supposed that coming from mtv films i should expect no less$\n",
      "i supposed that coming from mtv films i should expect no less\n",
      "['i', 'supposed', 'that', 'coming', 'from', 'mtv', 'films', 'i', 'should', 'expect', 'no', 'less']\n",
      "s\n"
     ]
    }
   ],
   "source": [
    "# Convert to lowercase and print the result\n",
    "movie_lower = movie.lower()\n",
    "print(movie_lower)\n",
    "\n",
    "# Remove specified character and print the result\n",
    "movie_no_sign = movie_lower.strip(\"$\")\n",
    "print(movie_no_sign)\n",
    "\n",
    "# Split the string into substrings and print the result\n",
    "movie_split = movie_no_sign.split()\n",
    "print(movie_split)\n",
    "\n",
    "# Select root word and print the result\n",
    "word_root = movie_split[1][0]\n",
    "print(word_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the film,however,is all good\n",
      "['the film', 'however', 'is all good']\n",
      "the film however is all good\n"
     ]
    }
   ],
   "source": [
    "movie = 'the film,however,is all good<\\\\i>'\n",
    "# Remove tags happening at the end and print results\n",
    "movie_tag = movie.rstrip(\"<\\i>\")\n",
    "print(movie_tag)\n",
    "\n",
    "# Split the string using commas and print results\n",
    "movie_no_comma = movie_tag.split(\",\")\n",
    "print(movie_no_comma)\n",
    "\n",
    "# Join back together and print results\n",
    "movie_join = ' '.join(movie_no_comma)\n",
    "print(movie_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mtv films election, a high school comedy, is a current example', 'from there, director steven spielberg wastes no time, taking us into the water on a midnight swim']\n",
      "['mtv films election', ' a high school comedy', ' is a current example']\n",
      "['from there', ' director steven spielberg wastes no time', ' taking us into the water on a midnight swim']\n"
     ]
    }
   ],
   "source": [
    "file = 'mtv films election, a high school comedy, is a current example\\nfrom there, director steven spielberg wastes no time, taking us into the water on a midnight swim'\n",
    "\n",
    "# Split string at line boundaries\n",
    "file_split = file.splitlines()\n",
    "\n",
    "# Print file_split\n",
    "print(file_split)\n",
    "\n",
    "# Complete for-loop to split by commas\n",
    "for substring in file_split:\n",
    "    substring_split = substring.split(sep=',')\n",
    "    print(substring_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding and replacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    it's clear that he's passionate about his beli...\n",
       "1    I believe you I always said that the actor act...\n",
       "2    it's astonishing how frightening the actor act...\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "movies = pd.Series([\n",
    "    \"it's clear that he's passionate about his beliefs , and that he's not just a punk looking for an excuse to beat people up .\"\n",
    "    , 'I believe you I always said that the actor actor actor is amazing in every movie he has played'\n",
    "    , \"it's astonishing how frightening the actor actor norton looks with a shaved head and a swastika on his chest.\"\n",
    "])\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word not found\n",
      "I believe you I always said that the actor is amazing in every movie he has played\n",
      "it's astonishing how frightening the actor norton looks with a shaved head and a swastika on his chest.\n"
     ]
    }
   ],
   "source": [
    "for movie in movies:\n",
    "  \t# If actor is not found between character 37 and 41 inclusive\n",
    "    # Print word not found\n",
    "    if movie.find(\"actor\", 37, 42) == -1:\n",
    "        print(\"Word not found\")\n",
    "    # Count occurrences and replace two with one\n",
    "    elif movie.count(\"actor\") == 2:  \n",
    "        print(movie.replace(\"actor actor\", \"actor\"))\n",
    "    else:\n",
    "        # Replace three occurrences with one\n",
    "        print(movie.replace(\"actor actor actor\", \"actor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "for movie in movies:\n",
    "  # Find the first occurrence of word\n",
    "  print(movie.find('money', 12, 51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substring not found\n",
      "substring not found\n",
      "substring not found\n"
     ]
    }
   ],
   "source": [
    "for movie in movies:\n",
    "  try:\n",
    "    # Find the first occurrence of word\n",
    "  \tprint(movie.index('money', 12, 51))\n",
    "  except ValueError:\n",
    "    print(\"substring not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natural Language Toolkit</td>\n",
       "      <td>suite of libraries and programs for symbolic a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TextBlob</td>\n",
       "      <td>Python library for processing textual data. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gensim</td>\n",
       "      <td>Gensim is a robust open-source vector space mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       tool                                        description\n",
       "0  Natural Language Toolkit  suite of libraries and programs for symbolic a...\n",
       "1                  TextBlob  Python library for processing textual data. It...\n",
       "2                    Gensim  Gensim is a robust open-source vector space mo..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df = pd.read_csv('./Datasets/wikipedia.csv', index_col=0)\n",
    "wiki_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df.iloc[3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tool computer science is used in artificial intelligence\n",
      "The tool artificial intelligence is used in computer science\n"
     ]
    }
   ],
   "source": [
    "wikipedia_article = wiki_df.iloc[3,1]\n",
    "my_list = []\n",
    "# Assign the substrings to the variables\n",
    "first_pos = wikipedia_article[3:19].lower()\n",
    "second_pos = wikipedia_article[21:44].lower()\n",
    "\n",
    "# Define string with placeholders \n",
    "my_list.append(\"The tool {} is used in {}\")\n",
    "\n",
    "# Define string with rearranged placeholders\n",
    "my_list.append(\"The tool {1} is used in {0}\")\n",
    "\n",
    "# Use format to print strings\n",
    "for my_string in my_list:\n",
    "  \tprint(my_string.format(first_pos, second_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you are interested in artificial intelligence, you can take the course related to neural networks\n"
     ]
    }
   ],
   "source": [
    "courses = ['artificial intelligence', 'neural networks']\n",
    "# Create a dictionary\n",
    "plan = {\n",
    "    \"field\": courses[0],\n",
    "    \"tool\": courses[1]\n",
    "}\n",
    "\n",
    "# Complete the placeholders accessing elements of field and tool keys in the data dictionary\n",
    "my_message = \"If you are interested in {data[field]}, you can take the course related to {data[tool]}\"\n",
    "\n",
    "# Use the plan dictionary to replace placeholders\n",
    "print(my_message.format(data=plan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning. Today is March 18, 2024. It's 16:15 ... time to work!\n"
     ]
    }
   ],
   "source": [
    "# Import datetime \n",
    "import datetime as dtt\n",
    "get_date = dtt.datetime.now()\n",
    "\n",
    "# Add named placeholders with format specifiers\n",
    "message = \"Good morning. Today is {today:%B %d, %Y}. It's {today:%H:%M} ... time to work!\"\n",
    "\n",
    "# Use the format method replacing the placeholder with get_date\n",
    "print(message.format(today=get_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatted String Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "field1 = 'sexiest job'\n",
    "field2 = 'data is produced daily'\n",
    "field3 = 'Individuals'\n",
    "\n",
    "fact1 = 21\n",
    "fact2 = 2500000000000000000\n",
    "fact3 = 72.41415415151\n",
    "fact4 = 1.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type Conversion Allowed:</br>\n",
    "!s(stringversion) </br>\n",
    "!r(stringcontainingaprintablerepresentation,i.e.withquotes)</br>\n",
    "!a(sameas!rbutescapethenon-ASCIIcharacters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is considered 'sexiest job' in the 21st century\n"
     ]
    }
   ],
   "source": [
    "# Complete the f-string\n",
    "print(f\"Data science is considered {field1!r} in the {fact1}st century\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 2.500000e+18 of data is produced daily in the world\n"
     ]
    }
   ],
   "source": [
    "# Complete the f-string\n",
    "print(f\"About {fact2:e} of {field2} in the world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individuals create around 72.41% of the data but only 1.1% is analyzed\n"
     ]
    }
   ],
   "source": [
    "# Complete the f-string\n",
    "print(f\"{field3} create around {fact3:.2f}% of the data but only {fact4:.1f}% is analyzed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "number1 = 120\n",
    "number2 = 7\n",
    "string1 = 'httpswww.datacamp.com'\n",
    "list_links = [\n",
    "    'www.news.com',\n",
    "\t\t'www.google.com',\n",
    "\t\t'www.yahoo.com',\n",
    "\t\t'www.bbc.com',\n",
    "\t\t'www.msn.com',\n",
    "\t\t'www.facebook.com',\n",
    "\t\t'www.news.google.com'\n",
    "\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 tweets were downloaded in 7 minutes indicating a speed of 17.1 tweets per min\n"
     ]
    }
   ],
   "source": [
    "# Include both variables and the result of dividing them \n",
    "print(f\"{number1} tweets were downloaded in {number2} minutes indicating a speed of {number1/number2:.1f} tweets per min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.datacamp.com\n"
     ]
    }
   ],
   "source": [
    "# Replace the substring https by an empty string\n",
    "print(f\"{string1.replace('https', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 5.83% of the posts contain links\n"
     ]
    }
   ],
   "source": [
    "# Divide the length of list by 120 rounded to two decimals\n",
    "print(f\"Only {len(list_links)*100/120:.2f}% of the posts contain links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "east = {'date': dtt.datetime(2007, 4, 20, 0, 0), 'price': 1232443}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price for a house in the east neighborhood was $1232443 in 04-20-2007\n"
     ]
    }
   ],
   "source": [
    "# Access values of date and price in east dictionary\n",
    "print(f\"The price for a house in the east neighborhood was ${east['price']} in {east['date']:%m-%d-%Y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string as strg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool1 = 'Natural Language Toolkit'\n",
    "tool2 = 'TextBlob'\n",
    "tool3 = 'Gensim'\n",
    "\n",
    "description1 = 'suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.'\n",
    "description2 = 'Python library for processing textual data. It provides a simple API for diving into common natural language processing tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.'\n",
    "description3 = 'robust open-source vector space modeling and topic modeling toolkit implemented in Python. It uses NumPy, SciPy and optionally Cython for performance. Gensim is specifically designed to handle large text collections, using data streaming and efficient incremental algorithms, which differentiates it from most other scientific software packages that only target batch and in-memory processing.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Toolkit is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.\n",
      "TextBlob is a Python library for processing textual data. It provides a simple API for diving into common natural language processing tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
      "Gensim is a robust open-source vector space modeling and topic modeling toolkit implemented in Python. It uses NumPy, SciPy and optionally Cython for performance. Gensim is specifically designed to handle large text collections, using data streaming and efficient incremental algorithms, which differentiates it from most other scientific software packages that only target batch and in-memory processing.\n"
     ]
    }
   ],
   "source": [
    "# Create a template\n",
    "wikipedia = strg.Template(\"$tool is a $description\")\n",
    "\n",
    "# Substitute variables in template\n",
    "print(wikipedia.substitute(tool=tool1, description=description1))\n",
    "print(wikipedia.substitute(tool=tool2, description=description2))\n",
    "print(wikipedia.substitute(tool=tool3, description=description3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are offering a 3-month beginner course on Natural Language Toolkit just for $ 20 monthly\n"
     ]
    }
   ],
   "source": [
    "tools = ['Natural Language Toolkit', '20', 'month']\n",
    "\n",
    "# Select variables\n",
    "our_tool = tools[0]\n",
    "our_fee = tools[1]\n",
    "our_pay = tools[2]\n",
    "\n",
    "# Create template\n",
    "course = strg.Template(\"We are offering a 3-month beginner course on $tool just for $$ $fee ${pay}ly\")\n",
    "\n",
    "# Substitute identifiers with three variables\n",
    "print(course.substitute(tool=our_tool, fee=our_fee, pay=our_pay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions for Pattern Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#movies', '#movies']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'#movies', \"Love #movies! I had fun yesterday going to the #movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nice Place to eat', \" I'LL come back\", ' Excellent meat', '']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'!',\"Nice Place to eat! I'LL come back! Excellent meat!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have a nice car and a nice house a nice neighborhood'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"yellow\", \"nice\" , \"I have a yellow car and a yellow house a yellow neighborhood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['User9', 'User8']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'User\\d', 'the winners are: User9, Unern, User8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Usern', 'UserB']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'User\\D', 'the winners are: User9, Usern, UserB, User8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['User9', 'Usern', 'UserB', 'User8']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'User\\w', 'the winners are: User9, Usern, UserB, User8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', ' ', ' ', ' ', ',', ' ', ' ', '$', ' ', '!']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\W', 'This shirt is on sale, only $5 today!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$5']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\W\\d', 'This shirt is on sale, only $5 today!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Science']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'Data\\sScience', 'I enjoy learning Data Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ice-cream']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'ice\\Scream', 'I love ice-cream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@robot9!', '@robot4&', '@robot9$', '@robot7%']\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis =  '@robot9! @robot4& I have a good feeling that the show isgoing to be amazing! @robot9$ @robot7%'\n",
    "# Write the regex\n",
    "regex = r\"@robot\\d\\W\"\n",
    "\n",
    "# Find all matches of regex\n",
    "print(re.findall(regex, sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User_mentions:2']\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis = \"Unfortunately one of those moments wasn't a giant squid monster. User_mentions:2, likes: 9, number of retweets: 7\"\n",
    "# Write a regex to obtain user mentions\n",
    "print(re.findall(r\"User_mentions:\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['likes: 9']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain number of likes\n",
    "print(re.findall(r\"likes:\\s\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number of retweets: 7']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain number of retweets\n",
    "print(re.findall(r\"number\\sof\\sretweets:\\s\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = 'He#newHis%newTin love with$newPscrappy. #8break%He is&newYmissing him@newLalready'\n",
    "# Write a regex to match pattern separating sentences\n",
    "regex_sentence = r\"\\W\\dbreak\\W\"\n",
    "\n",
    "# Replace the regex_sentence with a space\n",
    "sentiment_sub = re.sub(regex_sentence, ' ', sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He is in love with scrappy.  He is missing him already\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Write a regex to match pattern separating sentences\n",
    "regex_sentence = r\"\\W\\dbreak\\W\"\n",
    "\n",
    "# Replace the regex_sentence with a space\n",
    "sentiment_sub = re.sub(regex_sentence, \" \", sentiment_analysis)\n",
    "\n",
    "# Write a regex to match pattern separating words\n",
    "regex_words = r\"\\Wnew\\w\"\n",
    "\n",
    "# Replace the regex_words and print the result\n",
    "sentiment_final = re.sub(regex_words, ' ', sentiment_sub)\n",
    "print(sentiment_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4-3', '10-04']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = 'Date of start: 4-3. Date of registration: 10-04.'\n",
    "re.findall(r'\\d+-\\d+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@ameli!a', '@joh&&n', '@mary90']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = 'The concert was amazing! @ameli!a @joh&&n @mary90'\n",
    "re.findall(r'@\\w+\\W*\\w+', my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['color', 'colour']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The color of this image is amazing. However, the colour blue could be brighter'\n",
    "re.findall(r'colou?r', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-966-847-3131', '54-908-42-42424']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_number = \"John: 1-966-847-3131 Michelle:54-908-42-42424\"\n",
    "re.findall(r'\\d{1,2}-\\d{3}-\\d{2,3}-\\d{4,}', phone_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.tellyourstory.com']\n",
      "['@blueKnight39']\n",
      "[]\n",
      "['@anitaLopez98', '@MyredHat31']\n",
      "['https://radio.foxnews.com']\n",
      "['@YourBestCompany', '@foxRadio']\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis = [ \"Boredd. Colddd @blueKnight39 Internet keeps stuffing up. Save me! https://www.tellyourstory.com\",\n",
    "                      \"I had a horrible nightmare last night @anitaLopez98 @MyredHat31 which affected my sleep, now I'm really tired\",\n",
    "                      \"im lonely  keep me company @YourBestCompany! @foxRadio https://radio.foxnews.com 22 female, new york\"\n",
    "\t]\n",
    "\n",
    "# Import re module\n",
    "import re\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "\t# Write regex to match http links and print out result\n",
    "\tprint(re.findall(r\"http\\S+\", tweet))\n",
    "\n",
    "\t# Write regex to match user mentions and print out result\n",
    "\tprint(re.findall(r\"@\\w+\", tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex metacharacters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='4506'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '4506 people attend the show'\n",
    "re.search(r'\\d{4}', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='4506'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(r'\\d{4}', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(17, 18), match='3'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Yesterday, I saw 3 shows'\n",
    "re.search(r'\\d', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match(r'\\d', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www.domain.com']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = 'www.domain.com'\n",
    "re.findall(r'www.+com', txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the 80s', 'the 90s']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = 'the 80s music hit were so much better than the 90s'\n",
    "re.findall(r'the\\s\\d+s', my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the 80s']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^the\\s\\d+s', my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the 90s']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'the\\s\\d+s$', my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'lov',\n",
       " 'th',\n",
       " 'musi',\n",
       " 'o',\n",
       " 'Mr.Go',\n",
       " 'However',\n",
       " 'th',\n",
       " 'soun',\n",
       " 'wa',\n",
       " 'to',\n",
       " 'loud']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = 'I love the music of Mr.Go. However, the sound was too loud'\n",
    "re.split(r'.\\s', my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love the music of Mr.Go', 'However, the sound was too loud']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'\\.\\s', my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elephant', 'elephant']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = 'Elephants are the world\\'s largest land animal! I would love to see an elephant one day'\n",
    "re.findall(r'[Ee]lephant', my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elephant', 'elephant']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'Elephant|elephant', my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MaryJohn2', 'Clary3']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = 'Yesterday I spent my afternoon with my friends: MaryJohn2 Clary3'\n",
    "re.findall(r'[a-zA-Z]+\\d', my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is John Smoth. I live in London.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = 'My&name&is#John Smoth. I%live$in#London.'\n",
    "re.sub(r'[!@#$%^&*()]',' ', my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www.google.com']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = 'Bad website: www.123.com; Good website: www.google.com'\n",
    "re.findall(r'www[^0-9]+com', my_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy vs. non-greedy matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
