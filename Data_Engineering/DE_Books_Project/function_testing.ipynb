{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Books Data From Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    "    \"Referer\": 'https://www.amazon.com.au/',\n",
    "    \"Sec-Ch-Ua\": \"Not_A Brand\",\n",
    "    \"Sec-Ch-Ua-Mobile\": \"?0\",\n",
    "    \"Sec-Ch-Ua-Platform\": \"macOS\",\n",
    "    'User-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "def get_amazon_data_books(num_books=1000):\n",
    "    # Base URL of the Amazon search results for data science books\n",
    "    base_url = f\"https://www.amazon.com.au/s?k=data+engineering+books\"\n",
    "\n",
    "    books = []\n",
    "    seen_titles = set()  # To keep track of seen titles\n",
    "\n",
    "    page = 1\n",
    "\n",
    "    while len(books) < num_books:\n",
    "        url = f\"{base_url}&page={page}\"\n",
    "        \n",
    "        # Send a request to the URL\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Parse the content of the request with BeautifulSoup\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            \n",
    "            # Find book containers (you may need to adjust the class names based on the actual HTML structure)\n",
    "            book_containers = soup.find_all(\"div\", {\"class\": \"s-result-item\"})\n",
    "            \n",
    "            # Loop through the book containers and extract data\n",
    "            for book in book_containers:\n",
    "                title = book.find(\"span\", {\"class\": \"a-text-normal\"})\n",
    "                type = book.find(\"a\", {\"class\": \"a-size-base\"})\n",
    "                author = book.find(\"a\", {\"class\": \"a-size-base\"})\n",
    "                price = book.find(\"span\", {\"class\": \"a-price-whole\"})\n",
    "                rating = book.find(\"span\", {\"class\": \"a-icon-alt\"})\n",
    "                \n",
    "                if title and author and price and rating:\n",
    "                    book_title = title.text.strip()\n",
    "                    \n",
    "                    # Check if title has been seen before\n",
    "                    if book_title not in seen_titles:\n",
    "                        seen_titles.add(book_title)\n",
    "                        books.append({\n",
    "                            \"Title\": book_title,\n",
    "                            \"Type\": type.text.strip(),\n",
    "                            \"Author\": author.text.strip(),\n",
    "                            \"Price\": price.text.strip(),\n",
    "                            \"Rating\": rating.text.strip(),\n",
    "                        })\n",
    "            \n",
    "            # Increment the page number for the next iteration\n",
    "            page += 1\n",
    "        else:\n",
    "            print(\"Failed to retrieve the page\")\n",
    "            break\n",
    "\n",
    "    # Limit to the requested number of books\n",
    "    # books = books[:num_books]\n",
    "    \n",
    "    # Convert the list of dictionaries into a DataFrame\n",
    "    df = pd.DataFrame(books)\n",
    "    \n",
    "    # # Remove duplicates based on 'Title' column\n",
    "    df.drop_duplicates(subset=\"Title\", inplace=True)\n",
    "    df['Price'] = df['Price'].astype(float)\n",
    "    df[['Rating', 'Rating_Out_Of']] = df.loc[:,'Rating'].str.replace(' stars', '').str.split(' out of ', expand=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Present Data in Our Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "def read_book_data_from_postgres() -> pd.DataFrame:\n",
    "    # Connect to your local PostgreSQL database\n",
    "    connection = psycopg2.connect(\n",
    "        dbname='SuperStore',\n",
    "        user='postgres',\n",
    "        password='Welcome',\n",
    "        host='localhost',\n",
    "        port='5432'\n",
    "    )\n",
    "    \n",
    "    # Define the SQL query to retrieve data\n",
    "    read_query = \"\"\"\n",
    "    SELECT * FROM books\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query and fetch the data\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(read_query)\n",
    "    result = cursor.fetchall()\n",
    "    \n",
    "    # Fetch column names for the DataFrame\n",
    "    column_names = [desc[0] for desc in cursor.description]\n",
    "    \n",
    "    # Convert the result into a pandas DataFrame\n",
    "    df = pd.DataFrame(result, columns=column_names)\n",
    "    \n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Delta of Books Data to our Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_delta_to_db(new: pd.DataFrame, old: pd.DataFrame):\n",
    "    connection = psycopg2.connect(\n",
    "        dbname='SuperStore',\n",
    "        user='postgres',\n",
    "        password='Welcome',\n",
    "        host='localhost',\n",
    "        port='5432'\n",
    "    )\n",
    "    \n",
    "    df = new[~new.apply(tuple, 1).isin(old.apply(tuple,1))]\n",
    "\n",
    "    # from sqlalchemy import create_engine\n",
    "    # engine = create_engine('postgresql+psycopg2://postgres:Welcome@localhost:5432/SuperStore')\n",
    "\n",
    "    # df.to_sql('books', con=engine, index=False, if_exists='replace')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_data = get_amazon_data_books(100)\n",
    "current_data = read_book_data_from_postgres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fresh Data = 124 and Current data = 20\n"
     ]
    }
   ],
   "source": [
    "print(f'Fresh Data = {len(fresh_data)} and Current data = {len(current_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n"
     ]
    }
   ],
   "source": [
    "print(len(write_delta_to_db(fresh_data, current_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rating_Out_Of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ultimate Data Engineering with Databricks: Dev...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fundamentals of Person-Centred Healthcare Prac...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Production of Space</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fundamentals of Data Engineering: Plan and Bui...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cracking the Data Engineering Interview: Land ...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>MATLAB: A Practical Introduction to Programmin...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>94.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Database Development For Dummies</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Machine Learning on Kubernetes: A practical ha...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Windows 11 For Dummies</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>The Royal Marsden Manual of Clinical Nursing P...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>92.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title     Author  Price  \\\n",
       "0    Ultimate Data Engineering with Databricks: Dev...  Paperback   64.0   \n",
       "1    Fundamentals of Person-Centred Healthcare Prac...  Paperback   44.0   \n",
       "2                              The Production of Space  Paperback   49.0   \n",
       "3    Fundamentals of Data Engineering: Plan and Bui...  Paperback   42.0   \n",
       "4    Cracking the Data Engineering Interview: Land ...  Paperback   41.0   \n",
       "..                                                 ...        ...    ...   \n",
       "119  MATLAB: A Practical Introduction to Programmin...  Paperback   94.0   \n",
       "120                   Database Development For Dummies  Paperback   42.0   \n",
       "121  Machine Learning on Kubernetes: A practical ha...  Paperback   66.0   \n",
       "122                             Windows 11 For Dummies  Paperback   31.0   \n",
       "123  The Royal Marsden Manual of Clinical Nursing P...  Paperback   92.0   \n",
       "\n",
       "    Rating Rating_Out_Of  \n",
       "0      4.1             5  \n",
       "1      4.6             5  \n",
       "2      4.6             5  \n",
       "3      4.7             5  \n",
       "4      4.3             5  \n",
       "..     ...           ...  \n",
       "119    4.4             5  \n",
       "120    4.4             5  \n",
       "121    4.6             5  \n",
       "122    4.4             5  \n",
       "123    4.8             5  \n",
       "\n",
       "[124 rows x 5 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh_data[~fresh_data.apply(tuple, 1).isin(current_data.apply(tuple,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rating_OutOf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ultimate Data Engineering with Databricks: Dev...</td>\n",
       "      <td>Mayank Malhotra</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Designing Data-Intensive Applications: The Big...</td>\n",
       "      <td>Martin Kleppmann</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python Data Engineering Resources: Forge Your ...</td>\n",
       "      <td>Vajo Lukic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ace the Data Science Interview: 201 Real Inter...</td>\n",
       "      <td>Nick Singh</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Quality Fundamentals: A Practitioner's Gu...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fighting Churn with Data: The science and stra...</td>\n",
       "      <td>Carl S. Gold</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Engineering 101</td>\n",
       "      <td>Kindle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Storytelling with Data: A Data Visualization G...</td>\n",
       "      <td>Cole Nussbaumer Knaflic</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Mesh: Delivering Data-Driven Value at Scale</td>\n",
       "      <td>Zhamak Dehghani</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Modern Data Engineering with Apache Spark: A H...</td>\n",
       "      <td>Scott Haines</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title                   Author  \\\n",
       "0  Ultimate Data Engineering with Databricks: Dev...          Mayank Malhotra   \n",
       "1  Designing Data-Intensive Applications: The Big...         Martin Kleppmann   \n",
       "2  Python Data Engineering Resources: Forge Your ...               Vajo Lukic   \n",
       "3  Ace the Data Science Interview: 201 Real Inter...               Nick Singh   \n",
       "4  Data Quality Fundamentals: A Practitioner's Gu...                Paperback   \n",
       "5  Fighting Churn with Data: The science and stra...             Carl S. Gold   \n",
       "6                               Data Engineering 101                   Kindle   \n",
       "7  Storytelling with Data: A Data Visualization G...  Cole Nussbaumer Knaflic   \n",
       "8   Data Mesh: Delivering Data-Driven Value at Scale          Zhamak Dehghani   \n",
       "9  Modern Data Engineering with Apache Spark: A H...             Scott Haines   \n",
       "\n",
       "   Price Rating Rating_OutOf  \n",
       "0   37.0    4.1            5  \n",
       "1   49.0    4.7            5  \n",
       "2    0.0    4.7            5  \n",
       "3   38.0    4.5            5  \n",
       "4   45.0    4.1            5  \n",
       "5   56.0    4.4            5  \n",
       "6    0.0    3.9            5  \n",
       "7   26.0    4.6            5  \n",
       "8   43.0    4.5            5  \n",
       "9   30.0    4.1            5  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.copy()\n",
    "# df1.loc[:,'Rating'].str.replace(' stars', '').str.split(' out of ', expand=True)\n",
    "df1[['Rating', 'Rating_OutOf']] = df1.loc[:,'Rating'].str.replace(' stars', '').str.split(' out of ', expand=True)\n",
    "# df1.loc[:,'Rating'].str.replace(' stars', '').str.split(' out of ', expand=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ultimate Data Engineering with Databricks: Dev...</td>\n",
       "      <td>Mayank Malhotra</td>\n",
       "      <td>37.</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Designing Data-Intensive Applications: The Big...</td>\n",
       "      <td>Martin Kleppmann</td>\n",
       "      <td>49.</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python Data Engineering Resources: Forge Your ...</td>\n",
       "      <td>Vajo Lukic</td>\n",
       "      <td>0.</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ace the Data Science Interview: 201 Real Inter...</td>\n",
       "      <td>Nick Singh</td>\n",
       "      <td>38.</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Quality Fundamentals: A Practitioner's Gu...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>45.</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Engineering 101</td>\n",
       "      <td>Kindle</td>\n",
       "      <td>0.</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Storytelling with Data: A Data Visualization G...</td>\n",
       "      <td>Cole Nussbaumer Knaflic</td>\n",
       "      <td>26.</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Mesh: Delivering Data-Driven Value at Scale</td>\n",
       "      <td>Zhamak Dehghani</td>\n",
       "      <td>43.</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Modern Data Engineering with Apache Spark: A H...</td>\n",
       "      <td>Scott Haines</td>\n",
       "      <td>29.</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prompt Engineering for Generative AI: Future-P...</td>\n",
       "      <td>James Phoenix</td>\n",
       "      <td>53.</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title                   Author  \\\n",
       "0  Ultimate Data Engineering with Databricks: Dev...          Mayank Malhotra   \n",
       "1  Designing Data-Intensive Applications: The Big...         Martin Kleppmann   \n",
       "2  Python Data Engineering Resources: Forge Your ...               Vajo Lukic   \n",
       "3  Ace the Data Science Interview: 201 Real Inter...               Nick Singh   \n",
       "4  Data Quality Fundamentals: A Practitioner's Gu...                Paperback   \n",
       "5                               Data Engineering 101                   Kindle   \n",
       "6  Storytelling with Data: A Data Visualization G...  Cole Nussbaumer Knaflic   \n",
       "7   Data Mesh: Delivering Data-Driven Value at Scale          Zhamak Dehghani   \n",
       "8  Modern Data Engineering with Apache Spark: A H...             Scott Haines   \n",
       "9  Prompt Engineering for Generative AI: Future-P...            James Phoenix   \n",
       "\n",
       "  Price              Rating  \n",
       "0   37.  4.1 out of 5 stars  \n",
       "1   49.  4.7 out of 5 stars  \n",
       "2    0.  4.7 out of 5 stars  \n",
       "3   38.  4.5 out of 5 stars  \n",
       "4   45.  4.1 out of 5 stars  \n",
       "5    0.  3.9 out of 5 stars  \n",
       "6   26.  4.6 out of 5 stars  \n",
       "7   43.  4.5 out of 5 stars  \n",
       "8   29.  4.1 out of 5 stars  \n",
       "9   53.  4.5 out of 5 stars  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = f\"https://www.amazon.com/s?k=data+engineering+books\"\n",
    "\n",
    "books = []\n",
    "seen_titles = set()  # To keep track of seen titles\n",
    "\n",
    "page = 1\n",
    "response = requests.get(base_url, headers=headers)\n",
    "if response.status_code == 200:\n",
    "    # Parse the content of the request with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Find book containers (you may need to adjust the class names based on the actual HTML structure)\n",
    "    book_containers = soup.find_all(\"div\", {\"class\": \"s-result-item\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved data: 200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the API endpoint\n",
    "url = \"https://data.iowa.gov/resource/m3tr-qhgy.json\"\n",
    "\n",
    "# Send a GET request to the API endpoint\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON data\n",
    "    data = response.json()\n",
    "    \n",
    "    # Print the data (or process it as needed)\n",
    "    # for item in data:\n",
    "    #     print(item)\n",
    "    print(f\"Retrieved data: {response.status_code}\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve data: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m all_data \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m# List to store all records\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Send a GET request to the API endpoint with pagination parameters\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$offset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Check if the request was successful\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;66;03m# Parse the JSON data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\requests\\sessions.py:746\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 746\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\requests\\models.py:902\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 902\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\urllib3\\response.py:1057\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m-> 1057\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\urllib3\\response.py:1209\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1210\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[0;32m   1211\u001b[0m     chunk, decode_content\u001b[38;5;241m=\u001b[39mdecode_content, flush_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m )\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoded:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\urllib3\\response.py:1155\u001b[0m, in \u001b[0;36mHTTPResponse._handle_chunk\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     returned_chunk \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# amt > self.chunk_left\u001b[39;00m\n\u001b[1;32m-> 1155\u001b[0m     returned_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_left\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39m_safe_read(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# type: ignore[union-attr] # Toss the CRLF at the end of the chunk.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\http\\client.py:640\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[0;32m    634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 640\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[0;32m    642\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Define the API endpoint\n",
    "url = \"https://data.iowa.gov/resource/m3tr-qhgy.json\"\n",
    "\n",
    "# Initialize parameters for pagination\n",
    "limit = 1000  # Number of records per request (adjust based on API limits)\n",
    "offset = 0    # Starting point for each request\n",
    "all_data = [] # List to store all records\n",
    "\n",
    "while True:\n",
    "    # Send a GET request to the API endpoint with pagination parameters\n",
    "    response = requests.get(url, params={\"$limit\": limit, \"$offset\": offset})\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON data\n",
    "        data = response.json()\n",
    "        \n",
    "        # Break the loop if no more data is returned\n",
    "        if not data:\n",
    "            break\n",
    "        \n",
    "        # Append the data to the list\n",
    "        all_data.extend(data)\n",
    "        \n",
    "        # Increment the offset for the next request\n",
    "        offset += limit\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data: {response.status_code}\")\n",
    "        break\n",
    "\n",
    "# Convert the list of records to a DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"iowa_data.csv\", index=False)\n",
    "\n",
    "print(\"Data download complete. Saved to iowa_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdf\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  person          region\n",
      "0         Anthony Jacobs         Oceania\n",
      "1            Jack Lebron           North\n",
      "2         Kelly Williams            East\n",
      "3          Anna Andreadi         Central\n",
      "4            Chuck Magee           South\n",
      "5             Nora Preis    Central Asia\n",
      "6      Deborah Brumfield          Africa\n",
      "7        Shirley Daniels      North Asia\n",
      "8   Alejandro Ballentine  Southeast Asia\n",
      "9          Nicole Hansen          Canada\n",
      "10      Giulietta Dortch       Caribbean\n",
      "11          Larry Hughes            AMEA\n",
      "12        Matt Collister            West\n"
     ]
    }
   ],
   "source": [
    "df = read_book_data_from_postgres()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection = psycopg2.connect(\n",
    "    dbname='SuperStore',\n",
    "    user='postgres',\n",
    "    password='Welcome',\n",
    "    host='localhost',\n",
    "    port='5432'\n",
    ")\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql+psycopg2://postgres:Welcome@localhost:5432/SuperStore')\n",
    "\n",
    "df.to_sql('books', con=engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
